{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liutianlin/anaconda3/lib/python3.6/site-packages/brian2/core/variables.py:174: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return np.issubdtype(np.bool, self.dtype)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from brian2 import *\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "from sklearn import linear_model\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.signal\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/liutianlin/Desktop/Academics/MINDS/neuromorphic/reservoir_Demo/ECG/data/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_Dynapse_data(coreID,neuronID,Tm):\n",
    "    core_id_array = []\n",
    "    with open(coreID, 'r') as f:\n",
    "        for line in f:\n",
    "            core_id_array.append(int(line))\n",
    "        core_id_array = np.array(core_id_array)\n",
    "    \n",
    "    neuron_id_array = []\n",
    "    with open(neuronID, 'r') as f:\n",
    "        for line in f:\n",
    "            neuron_id_array.append(int(line))\n",
    "        neuron_id_array = np.array(neuron_id_array)\n",
    "\n",
    "\n",
    "    time_array = []\n",
    "    with open(Tm, 'r') as f:\n",
    "        for line in f:\n",
    "            time_array.append(int(line))\n",
    "        time_array = np.array(time_array)\n",
    "    \n",
    "    neuron_id_array0=neuron_id_array[core_id_array==0]\n",
    "    time_array0=time_array[core_id_array==0]\n",
    "    pulse_ts = time_array0[neuron_id_array0==1]\n",
    "\n",
    "    t_min = np.min(time_array)\n",
    "    t_max = np.max(time_array)\n",
    "\n",
    "    unit_t = 10**(-6)*second\n",
    "        \n",
    "    neuron_id_array = (core_id_array-1)*256+neuron_id_array\n",
    "    reservoir_neurons = neuron_id_array[core_id_array!=0]\n",
    "    spike_times = time_array[core_id_array!=0]\n",
    "\n",
    "    print(reservoir_neurons.shape)\n",
    "    print(spike_times.shape)\n",
    "    \n",
    "    return reservoir_neurons, spike_times\n",
    "\n",
    "def exp_smooth(spike_train, t_grid, alpha=2, inc = 1):\n",
    "    n_spike = len(spike_train)\n",
    "    n_t = len(t_grid)\n",
    "    i_spike = 0\n",
    "    i_t = 0\n",
    "    sig = 0\n",
    "    sig_list = []\n",
    "    sig_t =0\n",
    "    while i_t < n_t:\n",
    "        if i_spike >= n_spike:\n",
    "            delta_t = unit_t * (t_grid[i_t] - sig_t)/second\n",
    "            sig = sig/np.exp(alpha*delta_t)\n",
    "            sig_list.append(sig)\n",
    "            sig_t = t_grid[i_t]\n",
    "            i_t += 1\n",
    "        elif spike_train[i_spike] < t_grid[i_t]:\n",
    "            delta_t = unit_t * (spike_train[i_spike] - sig_t)/second\n",
    "            sig = sig/np.exp(alpha*delta_t)+inc\n",
    "            sig_t = spike_train[i_spike]\n",
    "            i_spike += 1\n",
    "        else:\n",
    "            delta_t = unit_t * (t_grid[i_t] - sig_t)/second\n",
    "            sig = sig/np.exp(alpha*delta_t)\n",
    "            sig_list.append(sig)\n",
    "            sig_t = t_grid[i_t]\n",
    "            i_t += 1\n",
    "    return sig_list   \n",
    "  \n",
    "\n",
    "  \n",
    "    \n",
    "def read_ECG(MatECG):\n",
    "\trate = scipy.io.loadmat(MatECG)\n",
    "\trate_key = list(rate.keys())\n",
    "\tecg_key = rate_key[3]\n",
    "\tecg_raw = rate[ecg_key]\n",
    "\treturn ecg_raw\n",
    "\n",
    "\n",
    "def read_target(trgtMat):\n",
    "\trate = scipy.io.loadmat(trgtMat)\n",
    "\trate_key = list(rate.keys())\n",
    "\ttrgt_key = rate_key[3]\n",
    "\ttrgt_raw = rate[trgt_key]\n",
    "\treturn trgt_raw\n",
    "\n",
    "\n",
    "def confusion_stat(confusion):\n",
    "\tTP = confusion[1,1]\n",
    "\tFN = confusion[1,0]\n",
    "\tFP = confusion[0,1]\n",
    "\tTN = confusion[0,0]\n",
    "\t#Accuracy \n",
    "\tACC = (TP + TN ) / (TP + FP + TN + FN)\n",
    "\t# sensitivity (recall)\n",
    "\tSEN = TP/(TP + FN)\n",
    "\t# precision\n",
    "\tPRE = TP/(TP + FP)\n",
    "\t# F1 score\n",
    "\tF1 = (2 * TP) / (2 * TP + FP + FN)\n",
    "\treturn ACC, SEN, PRE, F1\n",
    "    \n",
    "def binarize(y, thres):\n",
    "\ty_b = np.copy(y)\n",
    "\ty_b[y >= thres] = 1\n",
    "\ty_b[y < thres] = 0\n",
    "\treturn y_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjectNr = '203'\n",
    "\n",
    "os.chdir('/Users/liutianlin/Desktop/Academics/MINDS/neuromorphic/reservoir_Demo/ECG/data/' + subjectNr)\n",
    "\n",
    "\n",
    "inp = 'ECG_' + subjectNr\n",
    "trgt = 'Target_' + subjectNr\n",
    "\n",
    "beats = 'Beats_' + subjectNr\n",
    "\n",
    "\n",
    "myRangeDict = {\n",
    "'106' : np.arange(216000,540000),\n",
    "'119' : np.arange(216000,540000),\n",
    "'200' : np.arange(108000,432000),\n",
    "'201' : np.arange(86400,410400),\n",
    "'203' : np.arange(108000,432000),\n",
    "'223' : np.arange(194400,518400),\n",
    "'233' : np.arange(194400,518400)\n",
    "}\n",
    "\n",
    "myRange = myRangeDict[subjectNr] \n",
    "\n",
    "\n",
    "ecg = read_ECG(inp)[myRange] # the ecg signal in the range\n",
    "\n",
    "\n",
    "\n",
    "rPeaks = scipy.io.loadmat(beats)[beats].flatten()[myRange] # the gaussians of peaks in the range\n",
    "\n",
    "\n",
    "target = np.int_(read_target(trgt).flatten()[myRange]) # only first 15 min in this experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rPeaks = scipy.io.loadmat(beats)[beats].flatten()[myRange]\n",
    "\n",
    "trainLength = 2 * 108000\n",
    "\n",
    "rPeaks_train = rPeaks[:trainLength] \n",
    "rPeaks_test = rPeaks[trainLength:]\n",
    "ecg_train = ecg[:trainLength] \n",
    "ecg_test = ecg[trainLength:] \n",
    "\n",
    "\n",
    "rPeaks_train = rPeaks[:trainLength] \n",
    "rPeaks_test = rPeaks[trainLength:]\n",
    "\n",
    "target_train_pre = target[:trainLength] \n",
    "\n",
    "target_test_pre = target[trainLength:]\n",
    "\n",
    "\n",
    "target_train = target_train_pre[rPeaks_train.astype(int)==1]\n",
    "target_test = target_test_pre[rPeaks_test.astype(int)==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c1f735198>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "plotLim = 8000\n",
    "plt.close()\n",
    "plt.figure()\n",
    "plt.plot(ecg[:plotLim])\n",
    "plt.plot(rPeaks[:plotLim])\n",
    "plt.plot(target[:plotLim])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3356616,)\n",
      "(3356616,)\n"
     ]
    }
   ],
   "source": [
    "trainDataName = 'train_subject_' + subjectNr\n",
    "\n",
    "coreID = trainDataName + '_core_id.txt'\n",
    "neuronID = trainDataName + '_neuron_id.txt'\n",
    "Tm = trainDataName + \"_ts.txt\"\n",
    "\n",
    "reservoir_neurons_train, spike_times_train = read_Dynapse_data(coreID,neuronID,Tm) \n",
    "spike_times_train = spike_times_train - spike_times_train[0]\n",
    "\n",
    "unit_t = 10**(-6)*second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 45.95936584472656 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# smoothingParameter = 5\n",
    "# delay = 0.35\n",
    "\n",
    "smoothingParameter = 10\n",
    "delay = 0.1\n",
    "\n",
    "def func_train(i):\n",
    "    t_grid = (np.where(rPeaks_train.astype(int)==1)[0]/360 + delay) * 10**6\n",
    "    return exp_smooth(spike_times_train[reservoir_neurons_train ==i], t_grid, alpha= smoothingParameter)\n",
    "\n",
    "\n",
    "# p = Pool(20)\n",
    "p = Pool(10)\n",
    "\n",
    "start_time = time.time()\n",
    "result = p.map(func_train, range(768)) \n",
    "sicTrain = np.array(result)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the target:  1043\n"
     ]
    }
   ],
   "source": [
    "print('the length of the target: ', len(target_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nFold = 4\n",
    "\n",
    "# outSpanForTrainFold = int(len(target_train)/nFold)\n",
    "\n",
    "outSpanForTrainFold = int(len(target_train)/nFold)\n",
    "\n",
    "outAllIndices = set(np.arange(len(target_train)))\n",
    "\n",
    "\n",
    "trainIndicesAllFolds = []\n",
    "validationIndicesAllFolds = []\n",
    "\n",
    "for foldnr in np.arange(nFold):\n",
    "     \n",
    "    validationIndices= list(range(foldnr * outSpanForTrainFold, (foldnr + 1) * outSpanForTrainFold))\n",
    "    trainIndices = list(outAllIndices - set(validationIndices))\n",
    "    validationIndicesAllFolds.append(validationIndices)\n",
    "    trainIndicesAllFolds.append(trainIndices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACC_tr_all = []\n",
    "SEN_tr_all = []\n",
    "PRE_tr_all = []\n",
    "F1_tr_all = []\n",
    "ACC_ts_all = []\n",
    "SEN_ts_all = []\n",
    "PRE_ts_all = []\n",
    "F1_ts_all = []\n",
    "\n",
    "ridgeParameter = 1500\n",
    "\n",
    "binarize_thres = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== subject 203 ===================\n",
      "binarize_thres 0.35\n",
      "smoothing parameter 10\n",
      "ridge parameter 1500\n",
      "------------------------------------------\n",
      "av ACC train 0.89272030651341\n",
      "av SEN train 0.8187447827178095\n",
      "av PRE train 0.6913519835172465\n",
      "av F1 train 0.7494377708530054\n",
      "av ACC validation 0.8557692307692308\n",
      "av SEN validation 0.7529888897328904\n",
      "av PRE validation 0.630750965077655\n",
      "av F1 validation 0.6687830299471521\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "for foldNr in np.arange(nFold):\n",
    "\n",
    "    sicTrainFold = sicTrain[:,trainIndicesAllFolds[foldNr] ]\n",
    "    sicValidationFold = sicTrain[:,validationIndicesAllFolds[foldNr] ]\n",
    "\n",
    "    outTrainFold = target_train[trainIndicesAllFolds[foldNr]]\n",
    "    outValidationFold = target_train[validationIndicesAllFolds[foldNr]]\n",
    "\n",
    "    clf = Ridge(alpha = ridgeParameter)\n",
    "    clf.fit(np.mat(sicTrainFold).T, outTrainFold)\n",
    "    train_fold_prdct = clf.predict(np.mat(sicTrainFold).T )\n",
    "    round_train_fold_prdct = binarize(train_fold_prdct, binarize_thres)\n",
    "\n",
    "    \n",
    "    validation_fold_prdct = clf.predict(np.mat(sicValidationFold).T)\n",
    "    round_validation_fold_prdct = binarize(validation_fold_prdct, binarize_thres)\n",
    "\n",
    "    cnf_matrix_train = confusion_matrix(outTrainFold, round_train_fold_prdct)\n",
    "    cnf_matrix_validation = confusion_matrix(outValidationFold, round_validation_fold_prdct)\n",
    "\n",
    "    # confusion stats\n",
    "    ACC_tr, SEN_tr, PRE_tr, F1_tr = confusion_stat(cnf_matrix_train)\n",
    "    ACC_ts, SEN_ts, PRE_ts, F1_ts = confusion_stat(cnf_matrix_validation)\n",
    "    \n",
    "    ACC_tr_all.append(ACC_tr)\n",
    "    SEN_tr_all.append(SEN_tr)\n",
    "    PRE_tr_all.append(PRE_tr)\n",
    "    F1_tr_all.append(F1_tr)\n",
    "    ACC_ts_all.append(ACC_ts)\n",
    "    SEN_ts_all.append(SEN_ts)\n",
    "    PRE_ts_all.append(PRE_ts)\n",
    "    F1_ts_all.append(F1_ts)\n",
    "\n",
    "print('========== subject', subjectNr,'===================')\n",
    "print('binarize_thres', binarize_thres)\n",
    "print('smoothing parameter', smoothingParameter)\n",
    "print('ridge parameter', ridgeParameter)\n",
    "print('------------------------------------------')\n",
    "print('av ACC train', np.array(ACC_tr_all).mean())\n",
    "print('av SEN train', np.array(SEN_tr_all).mean())\n",
    "print('av PRE train', np.array(PRE_tr_all).mean())\n",
    "print('av F1 train', np.array(F1_tr_all).mean())\n",
    "\n",
    "print('av ACC validation', np.array(ACC_ts_all).mean())\n",
    "print('av SEN validation', np.array(SEN_ts_all).mean())\n",
    "print('av PRE validation', np.array(PRE_ts_all).mean())\n",
    "print('av F1 validation', np.array(F1_ts_all).mean())    \n",
    "print('==========================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c18779cf8>]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(validation_fold_prdct)\n",
    "plt.plot(outValidationFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c19844be0>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "plt.plot(train_fold_prdct)\n",
    "plt.plot(outTrainFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1675064,)\n",
      "(1675064,)\n"
     ]
    }
   ],
   "source": [
    "dataName = 'test_subject_' + subjectNr\n",
    "coreID = dataName + '_core_id.txt'\n",
    "neuronID = dataName + '_neuron_id.txt'\n",
    "Tm = dataName + \"_ts.txt\"\n",
    "\n",
    "reservoir_neurons_test, spike_times_test = read_Dynapse_data(coreID,neuronID,Tm)\n",
    "spike_times_test = spike_times_test - spike_times_test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 21.54413890838623 seconds ---\n"
     ]
    }
   ],
   "source": [
    "smoothingParameter_test =  smoothingParameter\n",
    "def func_test(i):\n",
    "    t_grid = (np.where(rPeaks_test.astype(int)==1)[0]/360 + delay) * 10**6\n",
    "    return exp_smooth(spike_times_test[reservoir_neurons_test==i], t_grid, alpha= smoothingParameter_test)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "p = Pool(10)\n",
    "start_time = time.time()\n",
    "sicTest = np.array(p.map(func_test, range(768))) \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============test========================\n",
      "============== subject 203 ==============\n",
      "smoothing parameter 10\n",
      "ridge parameter 1500\n",
      "binarize parameter 0.35\n",
      "------------------------------------------\n",
      "ACC all train 0.8849472674976031\n",
      "SEN all train 0.8137254901960784\n",
      "PRE all train 0.6693548387096774\n",
      "F1  all train 0.7345132743362832\n",
      "ACC test 0.8927835051546392\n",
      "SEN test 0.7938144329896907\n",
      "PRE test 0.7064220183486238\n",
      "F1  test 0.7475728155339806\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "ridgeParameter_test =  ridgeParameter\n",
    "binarize_thres_test = binarize_thres\n",
    "\n",
    "clf = Ridge(alpha = ridgeParameter_test)\n",
    "clf.fit(np.mat(sicTrain).T, target_train)\n",
    "\n",
    "train_prdct = clf.predict(np.mat(sicTrain).T)\n",
    "\n",
    "test_prdct = clf.predict(np.mat(sicTest).T)\n",
    "round_train_prdct = binarize(train_prdct, binarize_thres_test)\n",
    "\n",
    "round_test_prdct = binarize(test_prdct, binarize_thres_test)\n",
    "\n",
    "\n",
    "better_cnf_matrix_train = confusion_matrix(target_train, round_train_prdct)\n",
    "better_cnf_matrix_test = confusion_matrix(target_test, round_test_prdct)\n",
    "\n",
    "# confusion stats\n",
    "ACC_tr, SEN_tr, PRE_tr, F1_tr = confusion_stat(better_cnf_matrix_train)\n",
    "ACC_ts, SEN_ts, PRE_ts, F1_ts = confusion_stat(better_cnf_matrix_test)\n",
    "\n",
    "print('==============test========================')\n",
    "print('============== subject', subjectNr, '==============')\n",
    "print('smoothing parameter', smoothingParameter)\n",
    "print('ridge parameter', ridgeParameter_test)\n",
    "print('binarize parameter', binarize_thres_test)\n",
    "\n",
    "print('------------------------------------------')\n",
    "print('ACC all train', ACC_tr)\n",
    "print('SEN all train', SEN_tr)\n",
    "print('PRE all train', PRE_tr)\n",
    "print('F1  all train', F1_tr)\n",
    "\n",
    "print('ACC test', ACC_ts)\n",
    "print('SEN test', SEN_ts)\n",
    "print('PRE test', PRE_ts)\n",
    "print('F1  test', F1_ts)    \n",
    "print('==========================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c180b4828>]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(target_test)\n",
    "plt.plot(test_prdct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
